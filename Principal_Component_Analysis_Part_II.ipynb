{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component analysis - Part II\n",
    "Author: [Biswajit Sahoo](https://biswajitsahoo1111.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <td align=\"center\">\n",
    "    <a href=\"https://colab.research.google.com/github/biswajitsahoo1111/blog_notebooks/blob/master/Principal_Component_Analysis_Part_II.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run Python code in Google Colab</a>\n",
    "  </td>\n",
    "  <td align=\"center\">\n",
    "    <a href=\"https://www.dropbox.com/s/zkftnkv31neuxgq/Principal_Component_Analysis_Part_II.ipynb?dl=1\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download Python code</a>\n",
    "  </td>\n",
    "  <td align=\"center\">\n",
    "    <a href=\"https://www.dropbox.com/s/7bzat96tt6r9iks/Principal_component_analysis_part_II.Rmd?dl=1\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download R code (R Markdown)</a>\n",
    "  </td>\n",
    "  <td align=\"center\">\n",
    "    <a href=\"https://www.dropbox.com/s/u9gbbviswkfgmsj/pca_part_2_MATLAB_code.pdf?dl=1\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download MATLAB code</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is Part-II of a three part series post on PCA. Other parts of the series can be found at the links below. \n",
    "\n",
    "* [Part-I: Basic Theory of PCA](https://biswajitsahoo1111.github.io/post/principal-component-analysis-part-i/)\n",
    "* [Part-III: Reproducing results of a published paper on PCA](https://biswajitsahoo1111.github.io/post/principal-component-analysis-part-iii/)\n",
    "\n",
    "In this post, we will first apply built in commands to obtain results and then show how the same results can be obtained without using built-in commands. Through this post our aim is not to advocate the use of non-built-in functions. Rather, in our opinion, it enhances understanding by knowing what happens under the hood when a built-in function is called. In actual applications, readers should always use built functions as they are robust(almost always) and tested for efficiency. \n",
    "\n",
    "This post is written in R. Equivalent [MATLAB code](https://github.com/biswajitsahoo1111/PCA/blob/master/pca_part_II_MATLAB_codes.pdf) for the same can be obtained from this [link](https://github.com/biswajitsahoo1111/PCA/blob/master/pca_part_II_MATLAB_codes.pdf). \n",
    "\n",
    "We will use French food data form reference [2]. Refer to the paper to know about the original source of the data. We will apply different methods to this data and compare the result. As the dataset is pretty small, one way to load the data into R is to create a dataframe in R using the values in the paper. Another way is to first create a csv file and then read the file into R/MATLAB. We have used the later approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>children</th>\n",
       "      <th>bread</th>\n",
       "      <th>vegetables</th>\n",
       "      <th>fruit</th>\n",
       "      <th>meat</th>\n",
       "      <th>poultry</th>\n",
       "      <th>milk</th>\n",
       "      <th>wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue_collar</td>\n",
       "      <td>2</td>\n",
       "      <td>332</td>\n",
       "      <td>428</td>\n",
       "      <td>354</td>\n",
       "      <td>1437</td>\n",
       "      <td>526</td>\n",
       "      <td>247</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White_collar</td>\n",
       "      <td>2</td>\n",
       "      <td>293</td>\n",
       "      <td>559</td>\n",
       "      <td>388</td>\n",
       "      <td>1527</td>\n",
       "      <td>567</td>\n",
       "      <td>239</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Upper_class</td>\n",
       "      <td>2</td>\n",
       "      <td>372</td>\n",
       "      <td>767</td>\n",
       "      <td>562</td>\n",
       "      <td>1948</td>\n",
       "      <td>927</td>\n",
       "      <td>235</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue_collar</td>\n",
       "      <td>3</td>\n",
       "      <td>406</td>\n",
       "      <td>563</td>\n",
       "      <td>341</td>\n",
       "      <td>1507</td>\n",
       "      <td>544</td>\n",
       "      <td>324</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White_collar</td>\n",
       "      <td>3</td>\n",
       "      <td>386</td>\n",
       "      <td>608</td>\n",
       "      <td>396</td>\n",
       "      <td>1501</td>\n",
       "      <td>558</td>\n",
       "      <td>319</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Upper_class</td>\n",
       "      <td>3</td>\n",
       "      <td>438</td>\n",
       "      <td>843</td>\n",
       "      <td>689</td>\n",
       "      <td>2345</td>\n",
       "      <td>1148</td>\n",
       "      <td>243</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blue_collar</td>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>660</td>\n",
       "      <td>367</td>\n",
       "      <td>1620</td>\n",
       "      <td>638</td>\n",
       "      <td>414</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>White_collar</td>\n",
       "      <td>4</td>\n",
       "      <td>460</td>\n",
       "      <td>699</td>\n",
       "      <td>484</td>\n",
       "      <td>1856</td>\n",
       "      <td>762</td>\n",
       "      <td>400</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Upper_class</td>\n",
       "      <td>4</td>\n",
       "      <td>385</td>\n",
       "      <td>789</td>\n",
       "      <td>621</td>\n",
       "      <td>2366</td>\n",
       "      <td>1149</td>\n",
       "      <td>304</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blue_collar</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>776</td>\n",
       "      <td>423</td>\n",
       "      <td>1848</td>\n",
       "      <td>759</td>\n",
       "      <td>495</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>White_collar</td>\n",
       "      <td>5</td>\n",
       "      <td>584</td>\n",
       "      <td>995</td>\n",
       "      <td>548</td>\n",
       "      <td>2056</td>\n",
       "      <td>893</td>\n",
       "      <td>518</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Upper_class</td>\n",
       "      <td>5</td>\n",
       "      <td>515</td>\n",
       "      <td>1097</td>\n",
       "      <td>887</td>\n",
       "      <td>2630</td>\n",
       "      <td>1167</td>\n",
       "      <td>561</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  children  bread  vegetables  fruit  meat  poultry  milk  \\\n",
       "0    Blue_collar         2    332         428    354  1437      526   247   \n",
       "1   White_collar         2    293         559    388  1527      567   239   \n",
       "2    Upper_class         2    372         767    562  1948      927   235   \n",
       "3    Blue_collar         3    406         563    341  1507      544   324   \n",
       "4   White_collar         3    386         608    396  1501      558   319   \n",
       "5    Upper_class         3    438         843    689  2345     1148   243   \n",
       "6    Blue_collar         4    534         660    367  1620      638   414   \n",
       "7   White_collar         4    460         699    484  1856      762   400   \n",
       "8    Upper_class         4    385         789    621  2366     1149   304   \n",
       "9    Blue_collar         5    655         776    423  1848      759   495   \n",
       "10  White_collar         5    584         995    548  2056      893   518   \n",
       "11   Upper_class         5    515        1097    887  2630     1167   561   \n",
       "\n",
       "    wine  \n",
       "0    427  \n",
       "1    258  \n",
       "2    433  \n",
       "3    407  \n",
       "4    363  \n",
       "5    341  \n",
       "6    407  \n",
       "7    416  \n",
       "8    282  \n",
       "9    486  \n",
       "10   319  \n",
       "11   284  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food = pd.DataFrame(data = {\"class\": [\"Blue_collar\", \"White_collar\", \"Upper_class\", \"Blue_collar\", \"White_collar\", \"Upper_class\",\n",
    "                                      \"Blue_collar\", \"White_collar\", \"Upper_class\", \"Blue_collar\", \"White_collar\", \"Upper_class\"],\n",
    "                            \"children\": np.repeat([2,3,4,5], 3),\n",
    "                            \"bread\": [332, 293, 372, 406, 386, 438, 534, 460, 385, 655, 584, 515],\n",
    "                            \"vegetables\": [428, 559, 767, 563, 608, 843, 660, 699, 789, 776, 995, 1097],\n",
    "                            \"fruit\": [354, 388, 562, 341, 396, 689, 367, 484, 621, 423, 548, 887],\n",
    "                            \"meat\": [1437, 1527, 1948, 1507, 1501, 2345, 1620, 1856, 2366, 1848, 2056, 2630],\n",
    "                            \"poultry\": [526, 567, 927, 544, 558, 1148, 638, 762, 1149, 759, 893, 1167],\n",
    "                            \"milk\": [247, 239, 235, 324, 319, 243, 414, 400, 304, 495, 518, 561],\n",
    "                            \"wine\": [427, 258, 433, 407, 363, 341, 407, 416, 282, 486, 319, 284]})\n",
    "food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centered data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_food = food.iloc[:, 2:] - food.iloc[:, 2:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_food = cent_food / cent_food.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance PCA\n",
    "\n",
    "### Using built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_food_cov = PCA().fit(cent_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the result to a pandas dataframe to add row names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bread</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetables</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit</th>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meat</th>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultry</th>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1   PC2   PC3   PC4\n",
       "bread       0.07  0.58 -0.40  0.11\n",
       "vegetables  0.33  0.41  0.29  0.61\n",
       "fruit       0.30 -0.10  0.34 -0.40\n",
       "meat        0.75 -0.11 -0.07 -0.29\n",
       "poultry     0.47 -0.24 -0.38  0.33\n",
       "milk        0.09  0.63  0.23 -0.41\n",
       "wine       -0.06  0.14 -0.66 -0.31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = np.round(pca_food_cov.components_[0:4, :].T, 2),\n",
    "             index = food.columns[2:],\n",
    "             columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_scores_pca_food_cov = pca_food_cov.transform(cent_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-635.05, -120.89,  -21.14,  -68.97],\n",
       "       [-488.56, -142.33,  132.37,   34.91],\n",
       "       [ 112.03, -139.75,  -61.86,   44.19],\n",
       "       [-520.01,   12.05,    2.85,  -13.7 ],\n",
       "       [-485.94,    1.17,   65.75,   11.51],\n",
       "       [ 588.17, -188.44,  -71.85,   28.56],\n",
       "       [-333.95,  144.54,  -34.94,   10.07],\n",
       "       [ -57.51,   42.86,  -26.26,  -46.55],\n",
       "       [ 571.32, -206.76,  -38.45,    3.69],\n",
       "       [ -39.38,  264.47, -126.43,  -12.74],\n",
       "       [ 296.04,  235.92,   58.84,   87.43],\n",
       "       [ 992.83,   97.15,  121.13,  -78.39]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(factor_scores_pca_food_cov[:, :4], 2)  # We have printed only four PCs out of seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variances using built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274831.02,  26415.99,   6254.11,   2299.9 ,   2090.2 ,    338.39,\n",
       "           65.81])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress= True)\n",
    "np.round(pca_food_cov.explained_variance_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312295.43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum(pca_food_cov.explained_variance_), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of variance before and after transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total variance before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312295.43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum(food.iloc[:, 2:].var()), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total variance after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312295.43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum(np.var(factor_scores_pca_food_cov, axis  = 0, ddof = 1)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important observation is to see how variance of each variable before transformation changes into variance of principal components. Note that total variance in this process remains same as seen from above codes.\n",
    "\n",
    "#### Variance along variables before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bread          11480.606061\n",
       "vegetables     35789.090909\n",
       "fruit          27255.454545\n",
       "meat          156618.386364\n",
       "poultry        62280.515152\n",
       "milk           13718.750000\n",
       "wine            5152.628788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food.iloc[:, 2:].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that calculation of variance is unaffected by centering data matrix. So variance of original data matrix as well as centered data matrix is same. Check it for yourself. Now let's see how PCA transforms these variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274831.02</td>\n",
       "      <td>26415.99</td>\n",
       "      <td>6254.11</td>\n",
       "      <td>2299.9</td>\n",
       "      <td>2090.2</td>\n",
       "      <td>338.39</td>\n",
       "      <td>65.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1       PC2      PC3     PC4     PC5     PC6    PC7\n",
       "0  274831.02  26415.99  6254.11  2299.9  2090.2  338.39  65.81"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data= np.round(np.var(factor_scores_pca_food_cov, axis = 0, ddof = 1), 2).reshape(1, -1),\n",
    "             columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the same result using built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274831.02,  26415.99,   6254.11,   2299.9 ,   2090.2 ,    338.39,\n",
       "           65.81])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca_food_cov.explained_variance_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing covariance PCA manually using SVD\n",
    "\n",
    "SVD of a matrix $A$ is defined as\n",
    "\n",
    "$$A = U\\Sigma V^T$$\n",
    "\n",
    "$U$, $\\Sigma$ and $V$ matrices are factorization results of SVD. But oddly (and sadly) after computing SVD, `numpy` returns $U$, $\\Sigma$ and $V^T$ as result. So to get matrix $V$, we have to again take the transpose of the third result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V_transpose = np.linalg.svd(cent_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07, -0.58, -0.4 ,  0.11],\n",
       "       [ 0.33, -0.41,  0.29,  0.61],\n",
       "       [ 0.3 ,  0.1 ,  0.34, -0.4 ],\n",
       "       [ 0.75,  0.11, -0.07, -0.29],\n",
       "       [ 0.47,  0.24, -0.38,  0.33],\n",
       "       [ 0.09, -0.63,  0.23, -0.41],\n",
       "       [-0.06, -0.14, -0.66, -0.31]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(V_transpose[:4, :].T, 2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-635.05,  120.89,  -21.14,  -68.97],\n",
       "       [-488.56,  142.33,  132.37,   34.91],\n",
       "       [ 112.03,  139.75,  -61.86,   44.19],\n",
       "       [-520.01,  -12.05,    2.85,  -13.7 ],\n",
       "       [-485.94,   -1.17,   65.75,   11.51],\n",
       "       [ 588.17,  188.44,  -71.85,   28.56],\n",
       "       [-333.95, -144.54,  -34.94,   10.07],\n",
       "       [ -57.51,  -42.86,  -26.26,  -46.55],\n",
       "       [ 571.32,  206.76,  -38.45,    3.69],\n",
       "       [ -39.38, -264.47, -126.43,  -12.74],\n",
       "       [ 296.04, -235.92,   58.84,   87.43],\n",
       "       [ 992.83,  -97.15,  121.13,  -78.39]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(cent_food.values @ V_transpose.T[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274831.02,  26415.99,   6254.11,   2299.9 ,   2090.2 ,    338.39,\n",
       "           65.81])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(S ** 2 / 11, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data matrix contains 12 data points. So to find variance of principal components we have to divide the square of the diagonal matrix by 11. To know the theory behind it, refer [Part-I](https://biswajitsahoo1111.github.io/post/principal-component-analysis-part-i/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing covariance PCA using Eigen-decomposition (Not recommended)\n",
    "\n",
    "This procedure is not recommended because forming a covariance matrix is computationally not efficient for large matrices if data matrix contains smaller entries. So doing eigen analysis on covariance matrix may give erroneous results. However, for our example we can use it to obtain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eigh(np.cov(cent_food, rowvar = False, ddof = 1)) # Eigenvalues are in ascending order\n",
    "eigenvalues, eigenvectors = eigenvalues[len(eigenvalues)::-1], eigenvectors[:, len(eigenvalues)::-1]  # Eigenvalues are in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07,  0.58,  0.4 ,  0.11],\n",
       "       [-0.33,  0.41, -0.29,  0.61],\n",
       "       [-0.3 , -0.1 , -0.34, -0.4 ],\n",
       "       [-0.75, -0.11,  0.07, -0.29],\n",
       "       [-0.47, -0.24,  0.38,  0.33],\n",
       "       [-0.09,  0.63, -0.23, -0.41],\n",
       "       [ 0.06,  0.14,  0.66, -0.31]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eigenvectors[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 635.05, -120.89,   21.14,  -68.97],\n",
       "       [ 488.56, -142.33, -132.37,   34.91],\n",
       "       [-112.03, -139.75,   61.86,   44.19],\n",
       "       [ 520.01,   12.05,   -2.85,  -13.7 ],\n",
       "       [ 485.94,    1.17,  -65.75,   11.51],\n",
       "       [-588.17, -188.44,   71.85,   28.56],\n",
       "       [ 333.95,  144.54,   34.94,   10.07],\n",
       "       [  57.51,   42.86,   26.26,  -46.55],\n",
       "       [-571.32, -206.76,   38.45,    3.69],\n",
       "       [  39.38,  264.47,  126.43,  -12.74],\n",
       "       [-296.04,  235.92,  -58.84,   87.43],\n",
       "       [-992.83,   97.15, -121.13,  -78.39]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(cent_food.values @ eigenvectors[:, :4], 2)    # We have printed only first 4 principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274831.02,  26415.99,   6254.11,   2299.9 ,   2090.2 ,    338.39,\n",
       "           65.81])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eigenvalues, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the `np.cov()` command to compute the covariance matrix, compute it manually and perform its eigen analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix_manual_food = (1/11) * cent_food.T @ cent_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_values_new, eig_vectors_new = np.linalg.eigh(cov_matrix_manual_food)\n",
    "eig_values_new, eig_vectors_new = eig_values_new[len(eig_values_new)::-1], eig_vectors_new[:, len(eig_values_new)::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07,  0.58,  0.4 ,  0.11],\n",
       "       [-0.33,  0.41, -0.29,  0.61],\n",
       "       [-0.3 , -0.1 , -0.34, -0.4 ],\n",
       "       [-0.75, -0.11,  0.07, -0.29],\n",
       "       [-0.47, -0.24,  0.38,  0.33],\n",
       "       [-0.09,  0.63, -0.23, -0.41],\n",
       "       [ 0.06,  0.14,  0.66, -0.31]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eig_vectors_new[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274831.02,  26415.99,   6254.11,   2299.9 ,   2090.2 ,    338.39,\n",
       "           65.81])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eig_values_new, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation PCA\n",
    "\n",
    "When PCA is performed on a scaled data matrix (each variable is centered as well as variance of each variable is one), it is called correlation PCA. Before discussing correlation PCA we will take some time to see different ways in which we can obtain correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways to obtain correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using built-in command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.59,  0.2 ,  0.32],\n",
       "       [ 0.59,  1.  ,  0.86,  0.88],\n",
       "       [ 0.2 ,  0.86,  1.  ,  0.96],\n",
       "       [ 0.32,  0.88,  0.96,  1.  ],\n",
       "       [ 0.25,  0.83,  0.93,  0.98],\n",
       "       [ 0.86,  0.66,  0.33,  0.37],\n",
       "       [ 0.3 , -0.36, -0.49, -0.44]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.corrcoef(food.iloc[:, 2:], rowvar = False)[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>vegetables</th>\n",
       "      <th>fruit</th>\n",
       "      <th>meat</th>\n",
       "      <th>poultry</th>\n",
       "      <th>milk</th>\n",
       "      <th>wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bread</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetables</th>\n",
       "      <td>0.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meat</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultry</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bread  vegetables  fruit  meat  poultry  milk  wine\n",
       "bread        1.00        0.59   0.20  0.32     0.25  0.86  0.30\n",
       "vegetables   0.59        1.00   0.86  0.88     0.83  0.66 -0.36\n",
       "fruit        0.20        0.86   1.00  0.96     0.93  0.33 -0.49\n",
       "meat         0.32        0.88   0.96  1.00     0.98  0.37 -0.44\n",
       "poultry      0.25        0.83   0.93  0.98     1.00  0.23 -0.40\n",
       "milk         0.86        0.66   0.33  0.37     0.23  1.00  0.01\n",
       "wine         0.30       -0.36  -0.49 -0.44    -0.40  0.01  1.00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((1/11) * scale_food.T @ scale_food, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing correlation PCA using built-in function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_food_cor = PCA().fit(scale_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24,  0.62, -0.01, -0.54],\n",
       "       [ 0.47,  0.1 , -0.06, -0.02],\n",
       "       [ 0.45, -0.21,  0.15,  0.55],\n",
       "       [ 0.46, -0.14,  0.21, -0.05],\n",
       "       [ 0.44, -0.2 ,  0.36, -0.32],\n",
       "       [ 0.28,  0.52, -0.44,  0.45],\n",
       "       [-0.21,  0.48,  0.78,  0.31]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca_food_cor.components_.T[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.86, -0.36,  0.4 ,  0.36],\n",
       "       [-1.89, -1.79, -1.31, -0.16],\n",
       "       [-0.12, -0.73,  1.42,  0.2 ],\n",
       "       [-2.04,  0.32, -0.11,  0.1 ],\n",
       "       [-1.69, -0.16, -0.51,  0.16],\n",
       "       [ 1.69, -1.35,  0.99, -0.43],\n",
       "       [-0.93,  1.37, -0.28, -0.26],\n",
       "       [-0.25,  0.63,  0.27,  0.29],\n",
       "       [ 1.6 , -1.74,  0.1 , -0.4 ],\n",
       "       [ 0.22,  2.78,  0.57, -0.25],\n",
       "       [ 1.95,  1.13, -0.99, -0.32],\n",
       "       [ 4.32, -0.1 , -0.57,  0.72]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_scores_pca_food_cor = pca_food_cor.transform(scale_food)\n",
    "np.round(factor_scores_pca_food_cor[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variances along principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33, 1.83, 0.63, 0.13, 0.06, 0.02, 0.  ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca_food_cor.explained_variance_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca_food_cor.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of variance before and after transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total variance before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(scale_food.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total variance after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.999999999999999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.var(factor_scores_pca_food_cor, axis = 0, ddof = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve the same result is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(np.cov(factor_scores_pca_food_cor, rowvar = False, ddof = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important observation is to see how variance of each variable before transformation changes into variance of principal components. Note that total variance in this process remains same as seen from above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along variables before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bread         1.0\n",
       "vegetables    1.0\n",
       "fruit         1.0\n",
       "meat          1.0\n",
       "poultry       1.0\n",
       "milk          1.0\n",
       "wine          1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_food.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obvious as we have scaled the matrix. Now see how PCA transforms these variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.33</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PC1   PC2   PC3   PC4   PC5   PC6  PC7\n",
       "0  4.33  1.83  0.63  0.13  0.06  0.02  0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data= np.round(np.var(factor_scores_pca_food_cor, axis = 0, ddof = 1), 2).reshape(1, -1),\n",
    "             columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the same result using built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33, 1.83, 0.63, 0.13, 0.06, 0.02, 0.  ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca_food_cor.explained_variance_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing correlation PCA manually using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_cor, S_cor, V_cor_transpose = np.linalg.svd(scale_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24, -0.62,  0.01, -0.54],\n",
       "       [ 0.47, -0.1 ,  0.06, -0.02],\n",
       "       [ 0.45,  0.21, -0.15,  0.55],\n",
       "       [ 0.46,  0.14, -0.21, -0.05],\n",
       "       [ 0.44,  0.2 , -0.36, -0.32],\n",
       "       [ 0.28, -0.52,  0.44,  0.45],\n",
       "       [-0.21, -0.48, -0.78,  0.31]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(V_cor_transpose.T[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.86,  0.36, -0.4 ,  0.36],\n",
       "       [-1.89,  1.79,  1.31, -0.16],\n",
       "       [-0.12,  0.73, -1.42,  0.2 ],\n",
       "       [-2.04, -0.32,  0.11,  0.1 ],\n",
       "       [-1.69,  0.16,  0.51,  0.16],\n",
       "       [ 1.69,  1.35, -0.99, -0.43],\n",
       "       [-0.93, -1.37,  0.28, -0.26],\n",
       "       [-0.25, -0.63, -0.27,  0.29],\n",
       "       [ 1.6 ,  1.74, -0.1 , -0.4 ],\n",
       "       [ 0.22, -2.78, -0.57, -0.25],\n",
       "       [ 1.95, -1.13,  0.99, -0.32],\n",
       "       [ 4.32,  0.1 ,  0.57,  0.72]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(scale_food.values @ V_cor_transpose.T[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33, 1.83, 0.63, 0.13, 0.06, 0.02, 0.  ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(S_cor ** 2 /11, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.999999999999997"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(S_cor ** 2 /11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have to divide by 11 to get eigenvalues of correlation matrix. Check the formulation of correlation matrix using scaled data matrix to convince yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using eigen-decomposition (Not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_values_cor, eig_vectors_cor = np.linalg.eigh(np.corrcoef(scale_food, rowvar = False))\n",
    "eig_values_cor, eig_vectors_cor = eig_values_cor[len(eig_values_cor)::-1], eig_vectors_cor[:, len(eig_values_cor)::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24,  0.62,  0.01, -0.54],\n",
       "       [-0.47,  0.1 ,  0.06, -0.02],\n",
       "       [-0.45, -0.21, -0.15,  0.55],\n",
       "       [-0.46, -0.14, -0.21, -0.05],\n",
       "       [-0.44, -0.2 , -0.36, -0.32],\n",
       "       [-0.28,  0.52,  0.44,  0.45],\n",
       "       [ 0.21,  0.48, -0.78,  0.31]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eig_vectors_cor[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.86, -0.36, -0.4 ,  0.36],\n",
       "       [ 1.89, -1.79,  1.31, -0.16],\n",
       "       [ 0.12, -0.73, -1.42,  0.2 ],\n",
       "       [ 2.04,  0.32,  0.11,  0.1 ],\n",
       "       [ 1.69, -0.16,  0.51,  0.16],\n",
       "       [-1.69, -1.35, -0.99, -0.43],\n",
       "       [ 0.93,  1.37,  0.28, -0.26],\n",
       "       [ 0.25,  0.63, -0.27,  0.29],\n",
       "       [-1.6 , -1.74, -0.1 , -0.4 ],\n",
       "       [-0.22,  2.78, -0.57, -0.25],\n",
       "       [-1.95,  1.13,  0.99, -0.32],\n",
       "       [-4.32, -0.1 ,  0.57,  0.72]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(scale_food.values @ eig_vectors_cor[:, :4], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance along each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33, 1.83, 0.63, 0.13, 0.06, 0.02, 0.  ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(eig_values_cor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this post would help clear some of the confusions that a beginner might have while encountering PCA for the first time. Please send me a note if you find any errors.\n",
    "\n",
    "## References\n",
    "\n",
    "1. I.T. Jolliffe, Principal component analysis, 2nd ed, Springer, New York,2002.\n",
    "2. Abdi, H., & Williams, L. J. (2010). Principal component analysis. Wiley interdisciplinary reviews: computational statistics, 2(4), 433-459."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_24_env",
   "language": "python",
   "name": "tf_24_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
